use crate::config::Config;
use crate::sop::dispatch::SopCronCache;
use anyhow::Result;
use chrono::Utc;
use std::future::Future;
use std::path::PathBuf;
use std::sync::{Arc, Mutex};
use tokio::task::JoinHandle;
use tokio::time::Duration;

const STATUS_FLUSH_SECONDS: u64 = 5;

pub async fn run(config: Config, host: String, port: u16) -> Result<()> {
    let initial_backoff = config.reliability.channel_initial_backoff_secs.max(1);
    let max_backoff = config
        .reliability
        .channel_max_backoff_secs
        .max(initial_backoff);

    crate::health::mark_component_ok("daemon");

    if config.heartbeat.enabled {
        let _ =
            crate::heartbeat::engine::HeartbeatEngine::ensure_heartbeat_file(&config.workspace_dir)
                .await;
    }

    // â”€â”€ Shared SOP resources (single engine for all components) â”€â”€
    let sop_engine: Option<Arc<Mutex<crate::sop::SopEngine>>> =
        crate::tools::create_sop_engine(&config.sop, &config.workspace_dir);
    let sop_memory: Option<Arc<dyn crate::memory::traits::Memory>> = if sop_engine.is_some() {
        let mem = crate::memory::create_memory(&config.memory, &config.workspace_dir, None)
            .map_err(|e| {
                tracing::error!("SOP enabled but memory backend init failed: {e}");
                anyhow::anyhow!("SOP requires a working memory backend but init failed: {e}")
            })?;
        Some(Arc::from(mem) as Arc<dyn crate::memory::traits::Memory>)
    } else {
        None
    };
    let sop_audit: Option<Arc<crate::sop::SopAuditLogger>> = sop_memory
        .as_ref()
        .map(|m| Arc::new(crate::sop::SopAuditLogger::new(Arc::clone(m))));
    let sop_collector: Option<Arc<crate::sop::SopMetricsCollector>> =
        if let Some(ref mem) = sop_memory {
            match crate::sop::SopMetricsCollector::rebuild_from_memory(mem.as_ref()).await {
                Ok(c) => Some(Arc::new(c)),
                Err(e) => {
                    tracing::warn!(
                        "SOP metrics warm-start failed in daemon, using empty collector: {e}"
                    );
                    Some(Arc::new(crate::sop::SopMetricsCollector::new()))
                }
            }
        } else {
            None
        };
    #[cfg(feature = "ampersona-gates")]
    let gate_eval: Option<Arc<crate::sop::GateEvalState>> = if let Some(ref mem) = sop_memory {
        match crate::sop::GateEvalState::rebuild_from_memory(
            Arc::clone(mem),
            "zeroclaw",
            config.sop.gates_file.as_deref().map(std::path::Path::new),
            config.sop.gate_eval_interval_secs,
        )
        .await
        {
            Ok(g) => Some(Arc::new(g)),
            Err(e) => {
                tracing::warn!("Gate eval warm-start failed: {e}");
                None
            }
        }
    } else {
        None
    };
    #[cfg(not(feature = "ampersona-gates"))]
    let gate_eval: Option<()> = None;

    let sop_cron_cache: Option<SopCronCache> = sop_engine.as_ref().map(SopCronCache::from_engine);

    let mut handles: Vec<JoinHandle<()>> = vec![spawn_state_writer(config.clone())];

    // â”€â”€ Gateway â”€â”€
    {
        let gateway_cfg = config.clone();
        let gateway_host = host.clone();
        let engine_for_gw = sop_engine.clone();
        let audit_for_gw = sop_audit.clone();
        let collector_for_gw = sop_collector.clone();
        handles.push(spawn_component_supervisor(
            "gateway",
            initial_backoff,
            max_backoff,
            move || {
                let cfg = gateway_cfg.clone();
                let host = gateway_host.clone();
                let engine = engine_for_gw.clone();
                let audit = audit_for_gw.clone();
                let collector = collector_for_gw.clone();
                async move {
                    crate::gateway::run_gateway(&host, port, cfg, engine, audit, collector).await
                }
            },
        ));
    }

    // â”€â”€ Channels â”€â”€
    {
        if has_supervised_channels(&config) {
            let channels_cfg = config.clone();
            handles.push(spawn_component_supervisor(
                "channels",
                initial_backoff,
                max_backoff,
                move || {
                    let cfg = channels_cfg.clone();
                    async move { crate::channels::start_channels(cfg).await }
                },
            ));
        } else {
            crate::health::mark_component_ok("channels");
            tracing::info!("No real-time channels configured; channel supervisor disabled");
        }
    }

    // â”€â”€ Heartbeat â”€â”€
    if config.heartbeat.enabled {
        let heartbeat_cfg = config.clone();
        handles.push(spawn_component_supervisor(
            "heartbeat",
            initial_backoff,
            max_backoff,
            move || {
                let cfg = heartbeat_cfg.clone();
                async move { Box::pin(run_heartbeat_worker(cfg)).await }
            },
        ));
    }

    // â”€â”€ Scheduler â”€â”€
    if config.cron.enabled {
        let scheduler_cfg = config.clone();
        let engine_for_sched = sop_engine.clone();
        let audit_for_sched = sop_audit.clone();
        let cache_for_sched = sop_cron_cache.clone();
        let collector_for_sched = sop_collector.clone();
        // gate_eval is Option<Arc<_>> with ampersona-gates, Option<()> without
        #[allow(clippy::clone_on_copy)]
        let gate_eval_for_sched = gate_eval.clone();
        handles.push(spawn_component_supervisor(
            "scheduler",
            initial_backoff,
            max_backoff,
            move || {
                let cfg = scheduler_cfg.clone();
                let engine = engine_for_sched.clone();
                let audit = audit_for_sched.clone();
                let cache = cache_for_sched.clone();
                let collector = collector_for_sched.clone();
                #[allow(clippy::clone_on_copy)]
                let ge = gate_eval_for_sched.clone();
                async move {
                    crate::cron::scheduler::run(cfg, engine, audit, cache, collector, ge).await
                }
            },
        ));
    } else {
        crate::health::mark_component_ok("scheduler");
        tracing::info!("Cron disabled; scheduler supervisor not started");
    }

    // â”€â”€ MQTT SOP listener â”€â”€
    if let Some(ref mqtt_config) = config.channels_config.mqtt {
        if let (Some(ref engine), Some(ref audit)) = (&sop_engine, &sop_audit) {
            let mqtt_cfg = mqtt_config.clone();
            let engine_for_mqtt = Arc::clone(engine);
            let audit_for_mqtt = Arc::clone(audit);
            handles.push(spawn_component_supervisor(
                "mqtt",
                initial_backoff,
                max_backoff,
                move || {
                    let cfg = mqtt_cfg.clone();
                    let engine = Arc::clone(&engine_for_mqtt);
                    let audit = Arc::clone(&audit_for_mqtt);
                    async move {
                        crate::channels::mqtt::run_mqtt_sop_listener(&cfg, engine, audit).await
                    }
                },
            ));
        } else {
            tracing::warn!(
                "MQTT config present but SOP engine not available; MQTT listener disabled"
            );
        }
    }

    println!("ðŸ§  ZeroClaw daemon started");
    println!("   Gateway:  http://{host}:{port}");
    println!("   Components: gateway, channels, heartbeat, scheduler");
    println!("   Ctrl+C to stop");

    tokio::signal::ctrl_c().await?;
    crate::health::mark_component_error("daemon", "shutdown requested");

    for handle in &handles {
        handle.abort();
    }
    for handle in handles {
        let _ = handle.await;
    }

    Ok(())
}

pub fn state_file_path(config: &Config) -> PathBuf {
    config
        .config_path
        .parent()
        .map_or_else(|| PathBuf::from("."), PathBuf::from)
        .join("daemon_state.json")
}

fn spawn_state_writer(config: Config) -> JoinHandle<()> {
    tokio::spawn(async move {
        let path = state_file_path(&config);
        if let Some(parent) = path.parent() {
            let _ = tokio::fs::create_dir_all(parent).await;
        }

        let mut interval = tokio::time::interval(Duration::from_secs(STATUS_FLUSH_SECONDS));
        loop {
            interval.tick().await;
            let mut json = crate::health::snapshot_json();
            if let Some(obj) = json.as_object_mut() {
                obj.insert(
                    "written_at".into(),
                    serde_json::json!(Utc::now().to_rfc3339()),
                );
            }
            let data = serde_json::to_vec_pretty(&json).unwrap_or_else(|_| b"{}".to_vec());
            let _ = tokio::fs::write(&path, data).await;
        }
    })
}

fn spawn_component_supervisor<F, Fut>(
    name: &'static str,
    initial_backoff_secs: u64,
    max_backoff_secs: u64,
    mut run_component: F,
) -> JoinHandle<()>
where
    F: FnMut() -> Fut + Send + 'static,
    Fut: Future<Output = Result<()>> + Send + 'static,
{
    tokio::spawn(async move {
        let mut backoff = initial_backoff_secs.max(1);
        let max_backoff = max_backoff_secs.max(backoff);

        loop {
            crate::health::mark_component_ok(name);
            match run_component().await {
                Ok(()) => {
                    crate::health::mark_component_error(name, "component exited unexpectedly");
                    tracing::warn!("Daemon component '{name}' exited unexpectedly");
                    // Clean exit â€” reset backoff since the component ran successfully
                    backoff = initial_backoff_secs.max(1);
                }
                Err(e) => {
                    crate::health::mark_component_error(name, e.to_string());
                    tracing::error!("Daemon component '{name}' failed: {e}");
                }
            }

            crate::health::bump_component_restart(name);
            tokio::time::sleep(Duration::from_secs(backoff)).await;
            // Double backoff AFTER sleeping so first error uses initial_backoff
            backoff = backoff.saturating_mul(2).min(max_backoff);
        }
    })
}

async fn run_heartbeat_worker(config: Config) -> Result<()> {
    let observer: std::sync::Arc<dyn crate::observability::Observer> =
        std::sync::Arc::from(crate::observability::create_observer(&config.observability));
    let engine = crate::heartbeat::engine::HeartbeatEngine::new(
        config.heartbeat.clone(),
        config.workspace_dir.clone(),
        observer,
    );

    let interval_mins = config.heartbeat.interval_minutes.max(5);
    let mut interval = tokio::time::interval(Duration::from_secs(u64::from(interval_mins) * 60));

    loop {
        interval.tick().await;

        let tasks = engine.collect_tasks().await?;
        if tasks.is_empty() {
            continue;
        }

        for task in tasks {
            let prompt = format!("[Heartbeat Task] {task}");
            let temp = config.default_temperature;
            if let Err(e) = crate::agent::run(
                config.clone(),
                Some(prompt),
                None,
                None,
                temp,
                vec![],
                false,
            )
            .await
            {
                crate::health::mark_component_error("heartbeat", e.to_string());
                tracing::warn!("Heartbeat task failed: {e}");
            } else {
                crate::health::mark_component_ok("heartbeat");
            }
        }
    }
}

fn has_supervised_channels(config: &Config) -> bool {
    config
        .channels_config
        .channels_except_webhook()
        .iter()
        .any(|(_, ok)| *ok)
}

#[cfg(test)]
mod tests {
    use super::*;
    use tempfile::TempDir;

    fn test_config(tmp: &TempDir) -> Config {
        let config = Config {
            workspace_dir: tmp.path().join("workspace"),
            config_path: tmp.path().join("config.toml"),
            ..Config::default()
        };
        std::fs::create_dir_all(&config.workspace_dir).unwrap();
        config
    }

    #[test]
    fn state_file_path_uses_config_directory() {
        let tmp = TempDir::new().unwrap();
        let config = test_config(&tmp);

        let path = state_file_path(&config);
        assert_eq!(path, tmp.path().join("daemon_state.json"));
    }

    #[tokio::test]
    async fn supervisor_marks_error_and_restart_on_failure() {
        let handle = spawn_component_supervisor("daemon-test-fail", 1, 1, || async {
            anyhow::bail!("boom")
        });

        tokio::time::sleep(Duration::from_millis(50)).await;
        handle.abort();
        let _ = handle.await;

        let snapshot = crate::health::snapshot_json();
        let component = &snapshot["components"]["daemon-test-fail"];
        assert_eq!(component["status"], "error");
        assert!(component["restart_count"].as_u64().unwrap_or(0) >= 1);
        assert!(component["last_error"]
            .as_str()
            .unwrap_or("")
            .contains("boom"));
    }

    #[tokio::test]
    async fn supervisor_marks_unexpected_exit_as_error() {
        let handle = spawn_component_supervisor("daemon-test-exit", 1, 1, || async { Ok(()) });

        tokio::time::sleep(Duration::from_millis(50)).await;
        handle.abort();
        let _ = handle.await;

        let snapshot = crate::health::snapshot_json();
        let component = &snapshot["components"]["daemon-test-exit"];
        assert_eq!(component["status"], "error");
        assert!(component["restart_count"].as_u64().unwrap_or(0) >= 1);
        assert!(component["last_error"]
            .as_str()
            .unwrap_or("")
            .contains("component exited unexpectedly"));
    }

    #[test]
    fn detects_no_supervised_channels() {
        let config = Config::default();
        assert!(!has_supervised_channels(&config));
    }

    #[test]
    fn detects_supervised_channels_present() {
        let mut config = Config::default();
        config.channels_config.telegram = Some(crate::config::TelegramConfig {
            bot_token: "token".into(),
            allowed_users: vec![],
            stream_mode: crate::config::StreamMode::default(),
            draft_update_interval_ms: 1000,
            interrupt_on_new_message: false,
            mention_only: false,
        });
        assert!(has_supervised_channels(&config));
    }

    #[test]
    fn detects_dingtalk_as_supervised_channel() {
        let mut config = Config::default();
        config.channels_config.dingtalk = Some(crate::config::schema::DingTalkConfig {
            client_id: "client_id".into(),
            client_secret: "client_secret".into(),
            allowed_users: vec!["*".into()],
        });
        assert!(has_supervised_channels(&config));
    }

    #[test]
    fn detects_mattermost_as_supervised_channel() {
        let mut config = Config::default();
        config.channels_config.mattermost = Some(crate::config::schema::MattermostConfig {
            url: "https://mattermost.example.com".into(),
            bot_token: "token".into(),
            channel_id: Some("channel-id".into()),
            allowed_users: vec!["*".into()],
            thread_replies: Some(true),
            mention_only: Some(false),
        });
        assert!(has_supervised_channels(&config));
    }

    #[test]
    fn detects_qq_as_supervised_channel() {
        let mut config = Config::default();
        config.channels_config.qq = Some(crate::config::schema::QQConfig {
            app_id: "app-id".into(),
            app_secret: "app-secret".into(),
            allowed_users: vec!["*".into()],
        });
        assert!(has_supervised_channels(&config));
    }

    #[test]
    fn detects_nextcloud_talk_as_supervised_channel() {
        let mut config = Config::default();
        config.channels_config.nextcloud_talk = Some(crate::config::schema::NextcloudTalkConfig {
            base_url: "https://cloud.example.com".into(),
            app_token: "app-token".into(),
            webhook_secret: None,
            allowed_users: vec!["*".into()],
        });
        assert!(has_supervised_channels(&config));
    }
}
